{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.nn.functional as F\n",
    "import Levenshtein as L\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('all/train.npy', encoding='bytes')\n",
    "Y_train = np.load('all/character/train_labels.npy')\n",
    "X_dev = np.load('all/dev.npy', encoding='bytes')\n",
    "Y_dev = np.load('all/character/dev_labels.npy')\n",
    "vocab_map = np.load('all/character/vocab.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __getitem__(self,i):\n",
    "        if self.labels != None:\n",
    "            return torch.tensor(self.data[i]), torch.tensor(self.labels[i], dtype=torch.long)\n",
    "        else:\n",
    "            return torch.tensor(self.data[i])\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "def collate(seq_list):\n",
    "    \"\"\"\n",
    "    return: a batch sorted by decreasing order of length of sequences\n",
    "    inputs: (L_padded, batch_size, 40)\n",
    "    targets: list of targets\n",
    "    \"\"\"\n",
    "    inputs,targets = zip(*seq_list)\n",
    "    lens = [seq.shape[0] for seq in inputs]\n",
    "    seq_order = sorted(range(len(lens)), key=lens.__getitem__, reverse=True)\n",
    "    inputs = [inputs[i] for i in seq_order]\n",
    "    targets = [targets[i] for i in seq_order]\n",
    "    return inputs,targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial setting: listener layer:2, hidden: 128/direction;  speller layer: 1, hidden: 256\n",
    "#### after that: listener layer:3, hidden: 256; speller: *, hidden: 512 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size=512, embed_size=256, key_size=128, nlayers=2):\n",
    "        super(SpellerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.nlayers = nlayers\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # projection os state s\n",
    "        self.fc1 = nn.Linear(hidden_size, key_size)\n",
    "        \n",
    "        # 1st layer, input: cat(y_{i-1},context_{i-1}); h_0: s_{i-1}\n",
    "        self.rnns = nn.ModuleList([\n",
    "            nn.LSTMCell(embed_size+key_size if layer==0 else hidden_size, hidden_size) for layer in range(nlayers)\n",
    "        ])\n",
    "        \n",
    "        self.scoring = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, inputs, context, hidden_init=None):\n",
    "        \"\"\"\n",
    "        inputs: (L2_padded, batch_size), L2_padded = padded transcript length \n",
    "        key: (L_padded, bs, key_size)\n",
    "        value: (L_padded, bs, value_size)\n",
    "        query_init: (bs, hidden)\n",
    "        context: (batch_size, context_size)\n",
    "        outs: (L2_padded, bs, vocab_size)\n",
    "        hiddens: a list of (h_n, c_n), n = L2_padded\n",
    "        \"\"\"\n",
    "        embed = self.embed(inputs)   # (L2_padded, batch_size, embed_size)\n",
    "        hiddens = [None] * self.nlayers\n",
    "#         for (i,h) in enumerate(hidden_init):\n",
    "#             hiddens[i] = h\n",
    "        outs = []\n",
    "        \n",
    "        for y in embed: #(N, embed_size)\n",
    "            inp = torch.cat((y, context), 1)    # (N, embed+value)\n",
    "            h = inp\n",
    "            for (l, rnn) in enumerate(self.rnns):\n",
    "                h1, c1 = rnn(h, hiddens[l])\n",
    "                hiddens[l] = (h1,c1)\n",
    "                h = h1\n",
    "\n",
    "            outs.append(self.scoring(h))\n",
    "        \n",
    "        outs = torch.stack(outs, dim=0)  #(L2_padded, N, vocab_size)\n",
    "        return outs, hiddens\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionTrainer:\n",
    "    def __init__ (self, speller, train_loader, val_loader, max_epochs=1, run_id='exp'):\n",
    "        self.speller = speller.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "#         self.optimizer1 = torch.optim.ASGD(self.listener.parameters(), lr=0.01, weight_decay=0.02)\n",
    "        self.optimizer2 = torch.optim.Adam(self.speller.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=len(vocab_map)).to(DEVICE)\n",
    "    \n",
    "    def train(self):\n",
    "#         self.listener.train()\n",
    "        self.speller.train()\n",
    "        self.epochs += 1\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_num, (inputs, targets) in enumerate(self.train_loader):\n",
    "            epoch_loss += self.train_batch(inputs, targets)\n",
    "       \n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "   \n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "    \n",
    "    def train_batch(self, inputs, targets):\n",
    "        targets = rnn.pad_sequence(targets, padding_value=len(vocab_map)).to(DEVICE) # (L2_padded, bs)\n",
    "        context = torch.randn(BATCH_SIZE, 128)\n",
    "        outs,_ = self.speller(inputs=targets[:-1,:], context=context)\n",
    "        print('outs shape',outs.size())\n",
    "        print('target shape', targets.size())\n",
    "        \n",
    "        loss = self.criterion(outs.view(-1, outs.size(2)), targets[1:].view(-1))      \n",
    "        self.optimizer2.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer2.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def validate(self):\n",
    "        self.speller.eval()\n",
    "        val_loss = 0\n",
    "        ls = 0\n",
    "        dev_len = len(self.val_loader.dataset)\n",
    "        preds = []\n",
    "        trues = []\n",
    "        with torch.no_grad():\n",
    "            for batch_num, (inputs, targets) in enumerate(self.val_loader):\n",
    "                for t in targets:\n",
    "                    trues.append(t.cpu().numpy())\n",
    "                    \n",
    "                targets = rnn.pad_sequence(targets, padding_value=len(vocab_map)).to(DEVICE) # (L2_padded, bs)\n",
    "                context = torch.randn(BATCH_SIZE, 128)\n",
    "                outs,_ = self.speller(inputs=targets[:-1,:], context=context)\n",
    "            \n",
    "                loss = self.criterion(outs.view(-1, outs.size(2)), targets[1:].view(-1))\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                probs = F.softmax(outs.permute(1,0,2), dim=2) # (N, L2_padded, vocab_size)\n",
    "#                 print('probs0: ',probs[0])\n",
    "#                 print(torch.max(probs[0],dim=1))\n",
    "                pred = torch.argmax(probs, dim=2) # (N, L2_padded)\n",
    "#                 print(pred.size())\n",
    "                for p in pred:\n",
    "                    preds.append(p.cpu().numpy())\n",
    "                \n",
    "            for i in range(dev_len):\n",
    "                pred_i = preds[i]\n",
    "                true_i = trues[i][1:-1]\n",
    "#                 print(pred_i)\n",
    "                if 0 in pred_i:\n",
    "                    pred_i = pred_i[:pred_i.index(0)]\n",
    "\n",
    "                pred = \"\".join(vocab_map[o] for o in pred_i)\n",
    "                true = \"\".join(vocab_map[l] for l in true_i)\n",
    "                if i % 200 == 0:\n",
    "                    print('pred:', pred)\n",
    "                    print('true:', true)\n",
    "\n",
    "                ls += L.distance(pred, true)\n",
    "                \n",
    "            return val_loss, ls\n",
    "    \n",
    "    def save_model(self):\n",
    "        path2 = os.path.join('experiments', self.run_id, 'speller-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.speller.state_dict()}, path2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CharDataset(X_train[:4], Y_train[:4])\n",
    "devset = CharDataset(X_dev[:2], Y_dev[:2])\n",
    "train_loader = DataLoader(trainset, shuffle=True, batch_size=BATCH_SIZE, collate_fn = collate)\n",
    "dev_loader = DataLoader(devset, shuffle=True, batch_size=BATCH_SIZE, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1542154742\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "speller = SpellerModel(vocab_size=len(vocab_map)+1)\n",
    "trainer = AttentionTrainer(speller=speller, \n",
    "                           train_loader=train_loader, val_loader=dev_loader, \n",
    "                           max_epochs=NUM_EPOCHS, run_id=run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nature/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs shape torch.Size([75, 2, 33])\n",
      "target shape torch.Size([76, 2])\n",
      "outs shape torch.Size([79, 2, 33])\n",
      "target shape torch.Size([80, 2])\n",
      "[TRAIN]  Epoch [1/2]   Loss: 3.4714\n",
      "pred: t                                                                          \n",
      "true: numerous works of art are based on the story of the sacrifice of isaac\n",
      "Val loss: 3.3214735984802246, Val Levenshtein distance: 122\n",
      "Saving model for epoch 1, with Levenshtein distance: 122\n",
      "Time elapsed:  00:00:01\n",
      "outs shape torch.Size([79, 2, 33])\n",
      "target shape torch.Size([80, 2])\n",
      "outs shape torch.Size([78, 2, 33])\n",
      "target shape torch.Size([79, 2])\n",
      "[TRAIN]  Epoch [2/2]   Loss: 3.2889\n",
      "pred: t                                                                          \n",
      "true: numerous works of art are based on the story of the sacrifice of isaac\n",
      "Val loss: 2.9739253520965576, Val Levenshtein distance: 123\n",
      "Time elapsed:  00:00:01\n"
     ]
    }
   ],
   "source": [
    "best_dist = 1e30\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "\n",
    "    val_loss, dist = trainer.validate()\n",
    "    print('Val loss: {}, Val Levenshtein distance: {}'.format(val_loss, dist))\n",
    "    if dist < best_dist:\n",
    "        best_dist = dist\n",
    "        print(\"Saving model for epoch {}, with Levenshtein distance: {}\".format(epoch+1, best_dist))\n",
    "        trainer.save_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Time elapsed: ', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
