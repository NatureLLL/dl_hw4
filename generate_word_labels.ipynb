{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('all/train_transcripts.npy')\n",
    "dev = np.load('all/dev_transcripts.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!' '\"' '#' '$' '%' '&' \"'\" \"'Addario\" \"'Africaine\" \"'Andrade\"]\n"
     ]
    }
   ],
   "source": [
    "# x=np.load('/Users/nature/CMU/11785/HW/hw3p1/dataset/vocab.npy')\n",
    "# print(x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build word based dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "vocab.append('<|||>')  # sos or eos\n",
    "next_word_index = 1\n",
    "train_labels = []\n",
    "for sentence in train:\n",
    "    labels = [0]\n",
    "    for word in sentence:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "            labels.append(next_word_index)\n",
    "            next_word_index += 1\n",
    "        else:\n",
    "            labels.append(vocab.index(word))\n",
    "    labels.append(0)\n",
    "    train_labels.append(np.asarray(labels))\n",
    "train_labels = np.asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_labels = []\n",
    "for sentence in dev:\n",
    "    labels = [0]\n",
    "    for word in sentence:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "            labels.append(next_word_index)\n",
    "            next_word_index += 1\n",
    "        else:\n",
    "            labels.append(vocab.index(word))\n",
    "    labels.append(0)\n",
    "    dev_labels.append(np.asarray(labels))\n",
    "dev_labels = np.asarray(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|||>' 'THE' 'FEMALE' 'PRODUCES' 'A' 'LITTER' 'OF' 'TWO' 'TO' 'FOUR']\n"
     ]
    }
   ],
   "source": [
    "vocab = np.asarray(vocab)\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <|||>\n",
      "186 THEY\n",
      "18 ARE\n",
      "16940 DIGGING\n",
      "1354 OUT\n",
      "24 THEIR\n",
      "973 OLD\n",
      "16941 TRACTS\n",
      "774 COMMA\n",
      "3692 DOUBLE\n",
      "896 HYPHEN\n",
      "8948 CHECKING\n",
      "24 THEIR\n",
      "9782 STOCKPILES\n",
      "6 OF\n",
      "6984 CANNED\n",
      "1265 GOODS\n",
      "13 AND\n",
      "9656 TELLING\n",
      "5549 ANYONE\n",
      "173 WHO\n",
      "364 WILL\n",
      "3834 LISTEN\n",
      "2590 COLON\n",
      "140 THIS\n",
      "1083 COULD\n",
      "244 BE\n",
      "226 IT\n",
      "781 PERIOD\n",
      "0 <|||>\n",
      "[b'THEY' b'ARE' b'DIGGING' b'OUT' b'THEIR' b'OLD' b'TRACTS' b'COMMA'\n",
      " b'DOUBLE' b'HYPHEN' b'CHECKING' b'THEIR' b'STOCKPILES' b'OF' b'CANNED'\n",
      " b'GOODS' b'AND' b'TELLING' b'ANYONE' b'WHO' b'WILL' b'LISTEN' b'COLON'\n",
      " b'THIS' b'COULD' b'BE' b'IT' b'PERIOD']\n"
     ]
    }
   ],
   "source": [
    "for i in dev_labels[301]:\n",
    "    print(i,vocab[i])\n",
    "print(dev[301])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**vocab**: a list contain all words appeared in transcripts  \n",
    "**vocab\\[0\\] = \\<sos\\>,\\<eos\\>**  \n",
    "**train_labels, dev_labels**: np array contain the word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all/train_labels.npy',train_labels)\n",
    "np.save('all/dev_labels.npy',dev_labels)\n",
    "np.save('all/vocab.npy', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
