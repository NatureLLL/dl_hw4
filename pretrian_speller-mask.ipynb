{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, os, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.nn.functional as F\n",
    "import Levenshtein as L\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 10\n",
    "context = torch.randn(BATCH_SIZE, 128).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('all/train.npy', encoding='bytes')\n",
    "Y_train = np.load('all/character/train_labels.npy')\n",
    "X_dev = np.load('all/dev.npy', encoding='bytes')\n",
    "Y_dev = np.load('all/character/dev_labels.npy')\n",
    "vocab_map = np.load('all/character/vocab.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __getitem__(self,i):\n",
    "        if self.labels != None:\n",
    "            return torch.tensor(self.data[i]), torch.tensor(self.labels[i], dtype=torch.long)\n",
    "        else:\n",
    "            return torch.tensor(self.data[i])\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "def collate(seq_list):\n",
    "    \"\"\"\n",
    "    return: a batch sorted by decreasing order of length of sequences\n",
    "    inputs: (L_padded, batch_size, 40)\n",
    "    targets: list of targets\n",
    "    \"\"\"\n",
    "    inputs,targets = zip(*seq_list)\n",
    "    lens = [seq.shape[0] for seq in inputs]\n",
    "    seq_order = sorted(range(len(lens)), key=lens.__getitem__, reverse=True)\n",
    "    inputs = [inputs[i] for i in seq_order]\n",
    "    targets = [targets[i] for i in seq_order]\n",
    "    return inputs,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell_(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell_, self).__init__()\n",
    "        self.lstmcell = nn.LSTMCell(input_size, hidden_size, bias)\n",
    "        self.h_0 = nn.Parameter(torch.randn(1,hidden_size).to(DEVICE))\n",
    "        self.c_0 = nn.Parameter(torch.randn(1,hidden_size).to(DEVICE))\n",
    "        self.parameters = nn.ParameterList([self.h_0,self.c_0])\n",
    "    \n",
    "    def forward(self, inputs, t, hidden_states):\n",
    "        if t == 0:\n",
    "            hidden_states = (self.h_0.expand(inputs.size(0),-1), self.c_0.expand(inputs.size(0),-1))\n",
    "        hidden_state = self.lstmcell(inputs, hidden_states)\n",
    "        return hidden_state\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial setting: listener layer:2, hidden: 128/direction;  speller layer: 1, hidden: 256\n",
    "#### after that: listener layer:3, hidden: 256; speller: *, hidden: 512 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size=512, embed_size=256, key_size=128, nlayers=2):\n",
    "        super(SpellerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.nlayers = nlayers\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # projection os state s\n",
    "        self.fc1 = nn.Linear(hidden_size, key_size)\n",
    "        \n",
    "        # 1st layer, input: cat(y_{i-1},context_{i-1}); h_0: s_{i-1}\n",
    "        self.rnns = nn.ModuleList([\n",
    "            LSTMCell_(embed_size+key_size if layer==0 else hidden_size, hidden_size) for layer in range(nlayers)\n",
    "        ])\n",
    "#         print(self.rnns)\n",
    "        \n",
    "        # todo: cat(output, context)\n",
    "        self.scoring = nn.Linear(hidden_size+key_size, vocab_size)\n",
    "    \n",
    "    def forward(self, inputs, teacher=False, hidden_init=None):\n",
    "        \"\"\"\n",
    "        inputs: (L2_padded, batch_size), L2_padded = padded transcript length \n",
    "        key: (L_padded, bs, key_size)\n",
    "        value: (L_padded, bs, value_size)\n",
    "        query_init: (bs, hidden)\n",
    "        context: (batch_size, context_size)\n",
    "        outs: (L2_padded, bs, vocab_size)\n",
    "        hiddens: a list of (h_n, c_n), n = L2_padded\n",
    "        \"\"\"\n",
    "        L2_padded,N = inputs.size()\n",
    "    \n",
    "        embed = self.embed(inputs)   # (L2_padded, batch_size, embed_size)\n",
    "        hiddens = [None] * self.nlayers\n",
    "        outs = []\n",
    "        \n",
    "        for i in range(inputs.size(0)): \n",
    "            y = embed[i]\n",
    "            inp = torch.cat((y, context), 1)    # (N, embed+value)\n",
    "            h = inp\n",
    "            for (l, rnn) in enumerate(self.rnns):\n",
    "                h1, c1 = rnn(h, i, hiddens[l])\n",
    "                hiddens[l] = (h1,c1)\n",
    "                h = h1\n",
    "            \n",
    "            outs.append(self.scoring(torch.cat((h,context),1)))\n",
    "            \n",
    "        outs = torch.stack(outs, dim=0)  #(L2_padded, N, vocab_size)\n",
    "        return outs, hiddens\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionTrainer:\n",
    "    def __init__ (self, speller, train_loader, val_loader, max_epochs=1, run_id='exp'):\n",
    "        self.speller = speller.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.optimizer2 = torch.optim.Adam(self.speller.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduce='false').to(DEVICE)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer2, factor = 0.1, patience = 3, mode = 'min')\n",
    "    \n",
    "    def train(self):\n",
    "        self.speller.train()\n",
    "        self.epochs += 1\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_num, (inputs, targets) in enumerate(self.train_loader):\n",
    "            epoch_loss += self.train_batch(inputs, targets)\n",
    "       \n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "   \n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "    \n",
    "    def train_batch(self, inputs, targets):\n",
    "        trans_lens = [len(t) for t in targets]\n",
    "        targets = rnn.pad_sequence(targets, padding_value=0).to(DEVICE) # (L2_padded, bs) \n",
    "        \n",
    "        inp = targets[:-1,:]\n",
    "        mask = torch.ones(inp.size()).to(DEVICE)  # (L2_padded, bs)\n",
    "        for i in range(len(trans_lens)):\n",
    "            mask[trans_lens[i]-1:,i] = 0\n",
    "        \n",
    "        outs,_ = self.speller(inputs=inp)        \n",
    "        \n",
    "        loss = self.criterion(outs.view(-1, outs.size(2)), targets[1:,:].view(-1))    \n",
    "        loss = torch.sum(torch.mul(mask.view(-1), loss))\n",
    "        self.optimizer2.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer2.step()\n",
    "        \n",
    "        return loss.item() / len(trans_lens)\n",
    "    \n",
    "    def validate(self):\n",
    "        self.speller.eval()\n",
    "        val_loss = 0\n",
    "        ls = 0\n",
    "        dev_len = BATCH_SIZE * (len(self.val_loader.dataset) // BATCH_SIZE)\n",
    "        preds = []\n",
    "        trues = []\n",
    "        with torch.no_grad():\n",
    "            for batch_num, (inputs, targets) in enumerate(self.val_loader):\n",
    "                for t in targets:\n",
    "                    trues.append(t.cpu().numpy())\n",
    "                \n",
    "                trans_lens = [len(t) for t in targets]\n",
    "                targets = rnn.pad_sequence(targets, padding_value=0).to(DEVICE) # (L2_padded, bs) \n",
    "\n",
    "                inp = targets[:-1,:]\n",
    "                mask = torch.ones(inp.size()).to(DEVICE)  # (L2_padded, bs)\n",
    "                for i in range(len(trans_lens)):\n",
    "                    mask[trans_lens[i]-1:,i] = 0\n",
    "        \n",
    "                outs,_ = self.speller(inputs=inp)                      \n",
    "                loss = self.criterion(outs.view(-1, outs.size(2)), targets[1:,:].view(-1))    \n",
    "                loss = torch.sum(torch.mul(mask.view(-1), loss))           \n",
    "                val_loss += (loss.item() / len(trans_lens))\n",
    "                \n",
    "                probs = F.softmax(outs.permute(1,0,2), dim=2) # (N, L2_padded-1, vocab_size)\n",
    "                pred = torch.argmax(probs, dim=2) # (N, L2_padded-1)\n",
    "                for p in pred:\n",
    "                    preds.append(p.cpu().numpy())\n",
    "                \n",
    "            # compute L distance\n",
    "            for i in range(dev_len):\n",
    "                pred_i = preds[i]\n",
    "                true_i = trues[i][1:-1]   # exclude <sos> and <eos>\n",
    "                if 0 in pred_i:\n",
    "                    pred_i = pred_i[:pred_i.tolist().index(0)]\n",
    "\n",
    "                pred = \"\".join(vocab_map[o] for o in pred_i)\n",
    "                true = \"\".join(vocab_map[l] for l in true_i)\n",
    "                if i % 400 == 0:\n",
    "                    print('pred:', pred)\n",
    "                    print('true:', true)\n",
    "                ls += L.distance(pred, true)\n",
    "                \n",
    "            return val_loss / (batch_num + 1), ls / dev_len\n",
    "    \n",
    "    def save_model(self):\n",
    "        path2 = os.path.join('experiments', self.run_id, 'speller-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.speller.state_dict()}, path2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CharDataset(X_train, Y_train)\n",
    "devset = CharDataset(X_dev, Y_dev)\n",
    "\n",
    "train_loader = DataLoader(trainset, shuffle=True, batch_size=BATCH_SIZE, collate_fn = collate, drop_last=True)\n",
    "dev_loader = DataLoader(devset, batch_size=BATCH_SIZE, collate_fn = collate, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1542249795\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "speller = SpellerModel(vocab_size=len(vocab_map))\n",
    "checkpoint = torch.load('experiments/1542249216/speller-10.pkl')\n",
    "speller.load_state_dict(checkpoint['state_dict'])\n",
    "trainer = AttentionTrainer(speller=speller, \n",
    "                           train_loader=train_loader, val_loader=dev_loader, \n",
    "                           max_epochs=NUM_EPOCHS, run_id=run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (110080) to match target batch_size (109568).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-38011ec533f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-0309891c330f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-0309891c330f>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 862\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 1405\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   1406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (110080) to match target batch_size (109568)."
     ]
    }
   ],
   "source": [
    "best_dist = 1e30\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "\n",
    "    val_loss, dist = trainer.validate()\n",
    "    trainer.scheduler.step(val_loss)\n",
    "    print('Val loss: {}, Val Levenshtein distance: {}'.format(val_loss, dist))\n",
    "    if dist < best_dist:\n",
    "        best_dist = dist\n",
    "        print(\"Saving model for epoch {}, with Levenshtein distance: {}\".format(epoch+1, best_dist))\n",
    "        trainer.save_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Time elapsed: ', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
