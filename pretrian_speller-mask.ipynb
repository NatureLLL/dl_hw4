{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, os, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.nn.functional as F\n",
    "import Levenshtein as L\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 15\n",
    "context = torch.randn(BATCH_SIZE, 128).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('all/train.npy', encoding='bytes')\n",
    "Y_train = np.load('all/character/train_labels.npy')\n",
    "X_dev = np.load('all/dev.npy', encoding='bytes')\n",
    "Y_dev = np.load('all/character/dev_labels.npy')\n",
    "vocab_map = np.load('all/character/vocab.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __getitem__(self,i):\n",
    "        if self.labels != None:\n",
    "            return torch.tensor(self.data[i]), torch.tensor(self.labels[i], dtype=torch.long)\n",
    "        else:\n",
    "            return torch.tensor(self.data[i])\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "def collate(seq_list):\n",
    "    \"\"\"\n",
    "    return: a batch sorted by decreasing order of length of sequences\n",
    "    inputs: (L_padded, batch_size, 40)\n",
    "    targets: list of targets\n",
    "    \"\"\"\n",
    "    inputs,targets = zip(*seq_list)\n",
    "    lens = [seq.shape[0] for seq in inputs]\n",
    "    seq_order = sorted(range(len(lens)), key=lens.__getitem__, reverse=True)\n",
    "    inputs = [inputs[i] for i in seq_order]\n",
    "    targets = [targets[i] for i in seq_order]\n",
    "    return inputs,targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial setting: listener layer:2, hidden: 128/direction;  speller layer: 1, hidden: 256\n",
    "#### after that: listener layer:3, hidden: 256; speller: *, hidden: 512 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size=512, embed_size=256, key_size=128, nlayers=2):\n",
    "        super(SpellerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.nlayers = nlayers\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # projection os state s\n",
    "        self.fc1 = nn.Linear(hidden_size, key_size)\n",
    "        \n",
    "        # 1st layer, input: cat(y_{i-1},context_{i-1}); h_0: s_{i-1}\n",
    "        self.rnns = nn.ModuleList([\n",
    "            nn.LSTMCell(embed_size+key_size if layer==0 else hidden_size, hidden_size) for layer in range(nlayers)\n",
    "        ])\n",
    "        \n",
    "        self.scoring = nn.Linear(hidden_size, vocab_size)\n",
    "        self.weight_init()\n",
    "        \n",
    "    def weight_init(self):\n",
    "        torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform(self.scoring.weight)\n",
    "        self.fc1.bias.data.fill_(0.01)\n",
    "        self.scoring.bias.data.fill_(0.01)\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs, hidden_init=None):\n",
    "        \"\"\"\n",
    "        inputs: (L2_padded, batch_size), L2_padded = padded transcript length \n",
    "        key: (L_padded, bs, key_size)\n",
    "        value: (L_padded, bs, value_size)\n",
    "        query_init: (bs, hidden)\n",
    "        context: (batch_size, context_size)\n",
    "        outs: (L2_padded, bs, vocab_size)\n",
    "        hiddens: a list of (h_n, c_n), n = L2_padded\n",
    "        \"\"\"\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        embed = self.embed(inputs)   # (L2_padded, batch_size, embed_size)\n",
    "        hiddens = [None] * self.nlayers\n",
    "\n",
    "        # try teacher forcing \n",
    "#         if slef.training:\n",
    "#             p = np.random.random_sample()\n",
    "        \n",
    "        outs = []\n",
    "        for y in embed: #(N, embed_size)\n",
    "#             if slef.training:\n",
    "#                 if(np.random.random_sample()>0.9):\n",
    "#                     y = \n",
    "                \n",
    "            inp = torch.cat((y, context), dim=1)    # (N, embed+value)\n",
    "            h = inp\n",
    "            for (l, rnn) in enumerate(self.rnns):\n",
    "                h1, c1 = rnn(h, hiddens[l])\n",
    "                hiddens[l] = (h1,c1)\n",
    "                h = h1\n",
    "\n",
    "            outs.append(self.scoring(h))\n",
    "        \n",
    "        outs = torch.stack(outs, dim=0)  #(L2_padded, N, vocab_size)\n",
    "        return outs, hiddens\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionTrainer:\n",
    "    def __init__ (self, speller, train_loader, val_loader, max_epochs=1, run_id='exp'):\n",
    "        self.speller = speller.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.optimizer2 = torch.optim.Adam(self.speller.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduce='false').to(DEVICE)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer2, factor = 0.1, patience = 3, mode = 'min')\n",
    "    \n",
    "    def train(self):\n",
    "        self.speller.train()\n",
    "        self.epochs += 1\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_num, (inputs, targets) in enumerate(self.train_loader):\n",
    "            epoch_loss += self.train_batch(inputs, targets)\n",
    "       \n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "   \n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "    \n",
    "    def train_batch(self, inputs, targets):\n",
    "        lens = [len(t) for t in targets]\n",
    "        targets = rnn.pad_sequence(targets, padding_value=0).to(DEVICE) # (L2_padded, bs) \n",
    "        \n",
    "        inp = targets[:-1,:]\n",
    "        mask = torch.ones(inp.size()).to(DEVICE)  # (L2_padded, bs)\n",
    "        for i in range(len(lens)):\n",
    "            mask[lens[i]-1:,i] = 0\n",
    "        \n",
    "        outs,_ = self.speller(inputs=inp)        \n",
    "        \n",
    "        loss = self.criterion(outs.view(-1, outs.size(2)), targets[1:,:].view(-1))    \n",
    "        loss = torch.mean(torch.mul(mask.view(-1), loss))\n",
    "        self.optimizer2.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer2.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def validate(self):\n",
    "        self.speller.eval()\n",
    "        val_loss = 0\n",
    "        ls = 0\n",
    "        dev_len = BATCH_SIZE * (len(self.val_loader.dataset) // BATCH_SIZE)\n",
    "        preds = []\n",
    "        trues = []\n",
    "        with torch.no_grad():\n",
    "            for batch_num, (inputs, targets) in enumerate(self.val_loader):\n",
    "                for t in targets:\n",
    "                    trues.append(t.cpu().numpy())\n",
    "                \n",
    "                lens = [len(t) for t in targets]\n",
    "                targets = rnn.pad_sequence(targets, padding_value=0).to(DEVICE) # (L2_padded, bs) \n",
    "#                 mask = torch.ones(targets.size()).to(DEVICE)  # (L2_padded, bs)\n",
    "#                 for i in range(len(lens)):\n",
    "#                     mask[lens[i]:,i] = 0\n",
    "#                 outs,_ = self.speller(inputs=targets) \n",
    "                inp = targets[:-1,:]\n",
    "                mask = torch.ones(inp.size()).to(DEVICE)  # (L2_padded, bs)\n",
    "                for i in range(len(lens)):\n",
    "                    mask[lens[i]-1:,i] = 0\n",
    "        \n",
    "                outs,_ = self.speller(inputs=inp) \n",
    "                     \n",
    "                loss = self.criterion(outs.view(-1, outs.size(2)), targets[1:,:].view(-1))    \n",
    "                loss = torch.mean(torch.mul(mask.view(-1), loss))\n",
    "               \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                probs = F.softmax(outs.permute(1,0,2), dim=2) # (N, L2_padded-1, vocab_size)\n",
    "                pred = torch.argmax(probs, dim=2) # (N, L2_padded)\n",
    "                for p in pred:\n",
    "                    preds.append(p.cpu().numpy())\n",
    "                \n",
    "            for i in range(dev_len):\n",
    "                pred_i = preds[i]\n",
    "                true_i = trues[i][1:-1]   # trues include <sos> and <eos>\n",
    "                if 0 in pred_i:\n",
    "                    pred_i = pred_i[:pred_i.tolist().index(0)]\n",
    "\n",
    "                pred = \"\".join(vocab_map[o] for o in pred_i)\n",
    "                true = \"\".join(vocab_map[l] for l in true_i)\n",
    "                if i % 400 == 0:\n",
    "                    print('pred:', pred)\n",
    "                    print('true:', true)\n",
    "\n",
    "                ls += L.distance(pred, true)\n",
    "                \n",
    "            return val_loss / (batch_num + 1), ls / dev_len\n",
    "    \n",
    "    def save_model(self):\n",
    "        path2 = os.path.join('experiments', self.run_id, 'speller-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.speller.state_dict()}, path2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CharDataset(X_train, Y_train)\n",
    "devset = CharDataset(X_dev, Y_dev)\n",
    "\n",
    "train_loader = DataLoader(trainset, shuffle=True, batch_size=BATCH_SIZE, collate_fn = collate, drop_last=True)\n",
    "dev_loader = DataLoader(devset, batch_size=BATCH_SIZE, collate_fn = collate, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1542219735\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:22: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:23: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "speller = SpellerModel(vocab_size=len(vocab_map))\n",
    "checkpoint = torch.load('experiments/1542219735/speller-13.pkl')\n",
    "speller.load_state_dict(checkpoint['state_dict'])\n",
    "trainer = AttentionTrainer(speller=speller, \n",
    "                           train_loader=train_loader, val_loader=dev_loader, \n",
    "                           max_epochs=NUM_EPOCHS, run_id=run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [1/15]   Loss: 0.2447\n",
      "Val loss: 0.15197602659463882, Val Levenshtein distance: 26.94921875\n",
      "Saving model for epoch 1, with Levenshtein distance: 26.94921875\n",
      "Time elapsed:  00:00:38\n",
      "[TRAIN]  Epoch [2/15]   Loss: 0.2318\n",
      "Val loss: 0.1474117860198021, Val Levenshtein distance: 26.740234375\n",
      "Saving model for epoch 2, with Levenshtein distance: 26.740234375\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [3/15]   Loss: 0.2321\n",
      "Val loss: 0.1467825472354889, Val Levenshtein distance: 26.41015625\n",
      "Saving model for epoch 3, with Levenshtein distance: 26.41015625\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [4/15]   Loss: 0.2283\n",
      "Val loss: 0.1463848426938057, Val Levenshtein distance: 26.439453125\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [5/15]   Loss: 0.2299\n",
      "Val loss: 0.14604450017213821, Val Levenshtein distance: 26.4521484375\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [6/15]   Loss: 0.2306\n",
      "Val loss: 0.14587151259183884, Val Levenshtein distance: 26.25\n",
      "Saving model for epoch 6, with Levenshtein distance: 26.25\n",
      "Time elapsed:  00:00:38\n",
      "[TRAIN]  Epoch [7/15]   Loss: 0.2277\n",
      "Val loss: 0.14541161805391312, Val Levenshtein distance: 26.732421875\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [8/15]   Loss: 0.2246\n",
      "Val loss: 0.14509328454732895, Val Levenshtein distance: 26.2216796875\n",
      "Saving model for epoch 8, with Levenshtein distance: 26.2216796875\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [9/15]   Loss: 0.2254\n",
      "Val loss: 0.14492228627204895, Val Levenshtein distance: 26.6298828125\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [10/15]   Loss: 0.2280\n",
      "Val loss: 0.14458242803812027, Val Levenshtein distance: 26.201171875\n",
      "Saving model for epoch 10, with Levenshtein distance: 26.201171875\n",
      "Time elapsed:  00:00:38\n",
      "[TRAIN]  Epoch [11/15]   Loss: 0.2226\n",
      "Val loss: 0.14423811435699463, Val Levenshtein distance: 26.109375\n",
      "Saving model for epoch 11, with Levenshtein distance: 26.109375\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [12/15]   Loss: 0.2218\n",
      "Val loss: 0.14407312124967575, Val Levenshtein distance: 26.8662109375\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [13/15]   Loss: 0.2233\n",
      "Val loss: 0.14388679713010788, Val Levenshtein distance: 25.951171875\n",
      "Saving model for epoch 13, with Levenshtein distance: 25.951171875\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [14/15]   Loss: 0.2205\n",
      "Val loss: 0.14359048008918762, Val Levenshtein distance: 25.994140625\n",
      "Time elapsed:  00:00:39\n",
      "[TRAIN]  Epoch [15/15]   Loss: 0.2203\n",
      "Val loss: 0.14314339309930801, Val Levenshtein distance: 26.140625\n",
      "Time elapsed:  00:00:39\n"
     ]
    }
   ],
   "source": [
    "best_dist = 28\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "\n",
    "    val_loss, dist = trainer.validate()\n",
    "    trainer.scheduler.step(val_loss)\n",
    "    print('Val loss: {}, Val Levenshtein distance: {}'.format(val_loss, dist))\n",
    "    if dist < best_dist:\n",
    "        best_dist = dist\n",
    "        print(\"Saving model for epoch {}, with Levenshtein distance: {}\".format(epoch+1, best_dist))\n",
    "        trainer.save_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Time elapsed: ', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tn afe oioakh  toe corrent cf thes yime hmes hoaat  aomma dame hmes hraeeyd aavl typhen securd ng taape ioft-paren yeses anss tntiously poneh ng aeght-paren pomma ane hn teti ly phesk  tn toblh ca tiipn ng teriod\n",
      "true: as one breasts the current of this sometimes creamy comma sometimes awkward self hyphen regarding style left-parentheses it's obviously catching right-paren comma one inevitably thinks of death by drowning period\n",
      "pred: tn is one of the earliest agricultural villages yet discovered in southwest asia\n",
      "true: it is one of the earliest agricultural villages yet discovered in southwest asia\n",
      "pred: the e changes aroused orthodox opposition and sometimes government intervention\n",
      "true: these changes aroused orthodox opposition and sometimes government intervention\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14388679713010788, 25.951171875)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
