{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.nn.functional as F\n",
    "import Levenshtein as L\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('all/train.npy', encoding='bytes')\n",
    "Y_train = np.load('all/character/train_labels.npy')\n",
    "X_dev = np.load('all/dev.npy', encoding='bytes')\n",
    "Y_dev = np.load('all/character/dev_labels.npy')\n",
    "vocab_map = np.load('all/character/vocab.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __getitem__(self,i):\n",
    "        if self.labels != None:\n",
    "            return torch.tensor(self.data[i]), torch.tensor(self.labels[i], dtype=torch.long)\n",
    "        else:\n",
    "            return torch.tensor(self.data[i])\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "def collate(seq_list):\n",
    "    \"\"\"\n",
    "    return: a batch sorted by decreasing order of length of sequences\n",
    "    inputs: (L_padded, batch_size, 40)\n",
    "    targets: list of targets\n",
    "    \"\"\"\n",
    "    inputs,targets = zip(*seq_list)\n",
    "    lens = [seq.shape[0] for seq in inputs]\n",
    "    seq_order = sorted(range(len(lens)), key=lens.__getitem__, reverse=True)\n",
    "    inputs = [inputs[i] for i in seq_order]\n",
    "    targets = [targets[i] for i in seq_order]\n",
    "    return inputs,targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial setting: listener layer:2, hidden: 128/direction;  speller layer: 1, hidden: 256\n",
    "#### after that: listener layer:3, hidden: 256; speller: *, hidden: 512 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListenerModel(nn.Module):\n",
    "    def __init__(self, hidden_size=256, key_size=128, value_size=128, embed_size=40, nlayers=3):\n",
    "        super(ListenerModel, self).__init__()\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # todo: add conv layer\n",
    "        \n",
    "        self.rnns = nn.ModuleList([\n",
    "            nn.LSTM(embed_size if i==0 else hidden_size*4, hidden_size, num_layers=1, bidirectional=True) for i in range(nlayers)\n",
    "        ])\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size*4, key_size)\n",
    "        self.fc2 = nn.Linear(key_size, value_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        key: (L, N, key_size)\n",
    "        value: (L, N, value_size)\n",
    "        hidden: hidden state of last layer at t = L, (h_n, c_n); h_n, (num_direction,bs,hidden)\n",
    "        \"\"\"\n",
    "        batch_size = len(inputs)\n",
    "        lens = [len(s) for s in inputs] # actual lens of all sequences (already sorted) \n",
    "        # todo: add conv layer\n",
    "        padded_input = rnn.pad_sequence(inputs).to(DEVICE)  # (L_padded, N, 40)\n",
    "        out_packed = rnn.pack_padded_sequence(padded_input, lens)\n",
    "        for l in self.rnns:\n",
    "            out_packed, hidden = l(out_packed)\n",
    "            out_padded, _ = rnn.pad_packed_sequence(out_packed)\n",
    "            seq_len, batch_size, dim = out_padded.size()\n",
    "            if seq_len % 2 == 1:\n",
    "                out_padded = out_padded[:seq_len-1,:,:]\n",
    "                seq_len, batch_size, dim = out_padded.size()\n",
    "                lens[:] = [i-1 for i in lens]\n",
    "            print(out_padded.size())\n",
    "            out_padded = out_padded.permute(1,0,2).contiguous().view(batch_size, seq_len // 2, dim*2).permute(1,0,2)\n",
    "            lens[:] = [i // 2 for i in lens]\n",
    "            out_packed = rnn.pack_padded_sequence(out_padded, lens)   # (L_padded, N, hidden_size)\n",
    "        \n",
    "        key = self.fc1(out_padded)\n",
    "        value = self.fc2(key)\n",
    "        return key, value, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size=512, embed_size=256, key_size=128, nlayers=2):\n",
    "        super(SpellerModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.nlayers = nlayers\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # projection os state s\n",
    "        self.fc1 = nn.Linear(hidden_size, key_size)\n",
    "        \n",
    "        # 1st layer, input: cat(y_{i-1},context_{i-1}); h_0: s_{i-1}\n",
    "        self.rnns = nn.ModuleList([\n",
    "            nn.LSTMCell(embed_size+key_size if layer==0 else hidden_size, hidden_size) for layer in range(nlayers)\n",
    "        ])\n",
    "        \n",
    "        self.scoring = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, inputs, key, value, hidden_init):\n",
    "        \"\"\"\n",
    "        inputs: (L2_padded, batch_size), L2_padded = padded transcript length \n",
    "        key: (L_padded, bs, key_size)\n",
    "        value: (L_padded, bs, value_size)\n",
    "        query_init: (bs, hidden)\n",
    "        context: (batch_size, context_size)\n",
    "        outs: (L2_padded, bs, vocab_size)\n",
    "        hiddens: a list of (h_n, c_n), n = L2_padded\n",
    "        \"\"\"\n",
    "        key = key.permute(1, 2, 0)\n",
    "        value = value.permute(1, 0, 2)\n",
    "        print(inputs.size())\n",
    "        \n",
    "        embed = self.embed(inputs)   # (L2_padded, batch_size, embed_size)\n",
    "        hiddens = [None] * self.nlayers\n",
    "        for (i,h) in enumerate(hidden_init):\n",
    "            hiddens[i] = h\n",
    "        outs = []\n",
    "        \n",
    "        for y in embed: #(N, embed_size)\n",
    "            # create context\n",
    "            s,_ = hiddens[0]\n",
    "            query = self.fc1(s).unsqueeze(1)   # (N, 1, key_size)\n",
    "            # create context\n",
    "            energy = torch.bmm(query, key)  #(N, 1, L_padded)\n",
    "            attention = F.log_softmax(energy, 2)\n",
    "            context = torch.bmm(attention, value).squeeze()  #(N, value_size)\n",
    "            inp = torch.cat((y, context), 1)    # (N, embed+value)\n",
    "            h = inp\n",
    "            for (l, rnn) in enumerate(self.rnns):\n",
    "                h1, c1 = rnn(h, hiddens[l])\n",
    "                hiddens[l] = (h1,c1)\n",
    "                h = h1\n",
    "\n",
    "            outs.append(self.scoring(h))\n",
    "        \n",
    "        outs = torch.stack(outs, dim=0)  #(L2_padded, N, vocab_size)\n",
    "        return outs, hiddens\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionTrainer:\n",
    "    def __init__ (self, listener, speller, train_loader, val_loader, max_epochs=1, run_id='exp'):\n",
    "        self.listener = listener.to(DEVICE)\n",
    "        self.speller = speller.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.optimizer1 = torch.optim.ASGD(self.listener.parameters(), lr=0.01, weight_decay=0.02)\n",
    "        self.optimizer2 = torch.optim.Adam(self.speller.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=len(vocab_map)).to(DEVICE)\n",
    "    \n",
    "    def train(self):\n",
    "        self.listener.train()\n",
    "        self.speller.train()\n",
    "        self.epochs += 1\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_num, (inputs, targets) in enumerate(self.train_loader):\n",
    "            epoch_loss += self.train_batch(inputs, targets)\n",
    "       \n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "   \n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "    \n",
    "    def train_batch(self, inputs, targets):\n",
    "        # listener generates key/value, s_{-1},_ = hidden\n",
    "        key, value, hidden = self.listener(inputs)\n",
    "        a,bs,hs = hidden[0].size()\n",
    "        h_1 = hidden[0].permute(1,0,2).contiguous().view(-1,a*hs)\n",
    "        c_1 = hidden[1].permute(1,0,2).contiguous().view(-1,a*hs)\n",
    "        hidden_init = [(h_1, c_1)]\n",
    "        print('hidden init size',hidden_init[0][0].size())\n",
    "        \n",
    "        targets = rnn.pad_sequence(targets, padding_value=len(vocab_map)).to(DEVICE) # (L2_padded, bs)\n",
    "        outs,_ = self.speller(inputs=targets[:-1,:], key=key, value=value, hidden_init=hidden_init)\n",
    "        print('outs shape',outs.size())\n",
    "        print('target shape', targets.size())\n",
    "        \n",
    "        loss = self.criterion(outs.view(-1, outs.size(2)), targets[1:].view(-1))      \n",
    "        self.optimizer1.zero_grad()\n",
    "        self.optimizer2.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer1.step()\n",
    "        self.optimizer2.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def validate(self):\n",
    "        self.listener.eval()\n",
    "        self.speller.eval()\n",
    "        val_loss = 0\n",
    "        ls = 0\n",
    "        dev_len = len(self.val_loader.dataset)\n",
    "        preds = []\n",
    "        trues = []\n",
    "        with torch.no_grad():\n",
    "            for batch_num, (inputs, targets) in enumerate(self.val_loader):\n",
    "                key, value, hidden = self.listener(inputs)\n",
    "                a,bs,hs = hidden[0].size()\n",
    "                h_1 = hidden[0].permute(1,0,2).contiguous().view(-1,a*hs)\n",
    "                c_1 = hidden[1].permute(1,0,2).contiguous().view(-1,a*hs)\n",
    "                hidden_init = [(h_1, c_1)]\n",
    "                \n",
    "                for t in targets:\n",
    "                    trues.append(t.cpu().numpy())\n",
    "                    \n",
    "                targets = rnn.pad_sequence(targets, padding_value=len(vocab_map)).to(DEVICE) # (L2_padded, bs)\n",
    "\n",
    "                outs,_ = self.speller(inputs=targets[:-1,:], key=key, value=value, hidden_init=hidden_init)\n",
    "            \n",
    "                loss = self.criterion(outs.view(-1, outs.size(2)), targets[1:].view(-1))\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                probs = F.softmax(outs.permute(1,0,2), dim=2) # (N, L2_padded, vocab_size)\n",
    "                print('probs0: ',probs[0])\n",
    "                print(torch.max(probs[0],dim=1))\n",
    "                pred = torch.argmax(probs, dim=2) # (N, L2_padded)\n",
    "                print(pred.size())\n",
    "                for p in pred:\n",
    "                    preds.append(p.cpu().numpy())\n",
    "                \n",
    "            for i in range(dev_len):\n",
    "                pred_i = preds[i]\n",
    "                true_i = trues[i][1:-1]\n",
    "#                 print(pred_i)\n",
    "                if 0 in pred_i:\n",
    "                    pred_i = pred_i[:pred_i.index(0)]\n",
    "\n",
    "                pred = \"\".join(vocab_map[o] for o in pred_i)\n",
    "                true = \"\".join(vocab_map[l] for l in true_i)\n",
    "                print('pred:', pred)\n",
    "                print('true:', true)\n",
    "\n",
    "                ls += L.distance(pred, true)\n",
    "                \n",
    "            return val_loss, ls\n",
    "    \n",
    "    def save_model(self):\n",
    "        path1 = os.path.join('experiments', self.run_id, 'listenr-{}.pkl'.format(self.epochs))\n",
    "        path2 = os.path.join('experiments', self.run_id, 'speller-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.listener.state_dict()}, path1)\n",
    "        torch.save({'state_dict': self.speller.state_dict()}, path2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CharDataset(X_train[:4], Y_train[:4])\n",
    "devset = CharDataset(X_dev[:2], Y_dev[:2])\n",
    "train_loader = DataLoader(trainset, shuffle=True, batch_size=BATCH_SIZE, collate_fn = collate)\n",
    "dev_loader = DataLoader(devset, shuffle=True, batch_size=BATCH_SIZE, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1542142062\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = ListenerModel()\n",
    "speller = SpellerModel(vocab_size=len(vocab_map)+1)\n",
    "trainer = AttentionTrainer(listener=listener, speller=speller, \n",
    "                           train_loader=train_loader, val_loader=dev_loader, \n",
    "                           max_epochs=NUM_EPOCHS, run_id=run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nature/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([476, 2, 512])\n",
      "torch.Size([238, 2, 512])\n",
      "torch.Size([118, 2, 512])\n",
      "hidden init size torch.Size([2, 512])\n",
      "torch.Size([78, 2])\n",
      "outs shape torch.Size([78, 2, 33])\n",
      "target shape torch.Size([79, 2])\n",
      "torch.Size([524, 2, 512])\n",
      "torch.Size([262, 2, 512])\n",
      "torch.Size([130, 2, 512])\n",
      "hidden init size torch.Size([2, 512])\n",
      "torch.Size([79, 2])\n",
      "outs shape torch.Size([79, 2, 33])\n",
      "target shape torch.Size([80, 2])\n",
      "[TRAIN]  Epoch [1/1]   Loss: 3.3841\n",
      "torch.Size([466, 2, 512])\n",
      "torch.Size([232, 2, 512])\n",
      "torch.Size([116, 2, 512])\n",
      "torch.Size([75, 2])\n",
      "probs0:  tensor([[0.0272, 0.0347, 0.0285,  ..., 0.0278, 0.0265, 0.0270],\n",
      "        [0.0233, 0.0385, 0.0248,  ..., 0.0239, 0.0220, 0.0231],\n",
      "        [0.0204, 0.0407, 0.0221,  ..., 0.0209, 0.0187, 0.0203],\n",
      "        ...,\n",
      "        [0.0157, 0.0450, 0.0166,  ..., 0.0158, 0.0129, 0.0146],\n",
      "        [0.0157, 0.0450, 0.0166,  ..., 0.0158, 0.0130, 0.0146],\n",
      "        [0.0157, 0.0450, 0.0165,  ..., 0.0158, 0.0130, 0.0147]])\n",
      "(tensor([0.0521, 0.0851, 0.1179, 0.1425, 0.1604, 0.1734, 0.1824, 0.1872, 0.1905,\n",
      "        0.1914, 0.1936, 0.1968, 0.1985, 0.1984, 0.1988, 0.1978, 0.1999, 0.2007,\n",
      "        0.1986, 0.1990, 0.2009, 0.2001, 0.1991, 0.1996, 0.2014, 0.2016, 0.2000,\n",
      "        0.1995, 0.2003, 0.2012, 0.2016, 0.2022, 0.2007, 0.2023, 0.2023, 0.2007,\n",
      "        0.2002, 0.2004, 0.2010, 0.1998, 0.2008, 0.2003, 0.2025, 0.2034, 0.2033,\n",
      "        0.2012, 0.2028, 0.2031, 0.2007, 0.2002, 0.2005, 0.2012, 0.1999, 0.2009,\n",
      "        0.2012, 0.2008, 0.2024, 0.2020, 0.2027, 0.2017, 0.2011, 0.2015, 0.2003,\n",
      "        0.2023, 0.2029, 0.2006, 0.2008, 0.2016, 0.2017, 0.2018, 0.2014, 0.2008,\n",
      "        0.2017, 0.2017, 0.2016]), tensor([29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
      "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
      "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
      "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
      "        29, 29, 29]))\n",
      "torch.Size([2, 75])\n",
      "pred:                                                                            \n",
      "true: numerous works of art are based on the story of the sacrifice of isaac\n",
      "pred:                                                                            \n",
      "true: the female produces a litter of two to four young in november and december\n",
      "Val loss: 2.992067813873291, Val Levenshtein distance: 124\n",
      "Saving model for epoch 1, with Levenshtein distance: 124\n",
      "Time elapsed:  00:00:08\n"
     ]
    }
   ],
   "source": [
    "best_dist = 1e30\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "\n",
    "    val_loss, dist = trainer.validate()\n",
    "    print('Val loss: {}, Val Levenshtein distance: {}'.format(val_loss, dist))\n",
    "    if dist < best_dist:\n",
    "        best_dist = dist\n",
    "        print(\"Saving model for epoch {}, with Levenshtein distance: {}\".format(epoch+1, best_dist))\n",
    "        trainer.save_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Time elapsed: ', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "print(vocab_map[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
